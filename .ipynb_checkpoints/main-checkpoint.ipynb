{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import os\n",
    "import paddle.vision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# 定义展示图片函数\n",
    "def show_images(imgs_paths=[],cols=4):\n",
    "    num_samples = len(imgs_paths)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    i = 0\n",
    "    for img_path in imgs_paths:\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(int(num_samples/cols + 1), cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        i += 1\n",
    "imgs_paths = [\n",
    "    \"/dataset/OPIXray/train/train_image/009000.jpg\"\n",
    "]\n",
    "show_images(imgs_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "import os\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.vision as V\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from paddle.io import DataLoader\n",
    "\n",
    "# 这里我们不需要用到图像标签，可以直接用paddle.vision里面提供的数据集接口\n",
    "def get_data(args):\n",
    "    transforms = V.transforms.Compose([\n",
    "        V.transforms.Resize(80),  # args.image_size + 1/4 *args.image_size\n",
    "        V.transforms.RandomResizedCrop(args.image_size, scale=(0.8, 1.0)),\n",
    "        V.transforms.ToTensor(),\n",
    "        V.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    dataset = V.datasets.ImageFolder(args.dataset_path, transform=transforms)\n",
    "    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"ddpm\"\"\"\n",
    "import os\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from paddle import optimizer\n",
    "# from utils import *\n",
    "from modules import UNet    # 模型\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=500, beta_start=1e-4, beta_end=0.02, img_size=64, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule()\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = paddle.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return paddle.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = paddle.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = paddle.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = paddle.randn(shape=x.shape)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return paddle.randint(low=1, high=self.noise_steps, shape=(n,))\n",
    "\n",
    "    def sample(self, model, n):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with paddle.no_grad():\n",
    "            x = paddle.randn((n, 3, self.img_size, self.img_size))\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "\n",
    "\n",
    "                t = paddle.to_tensor([i] * x.shape[0]).astype(\"int64\")\n",
    "                # print(x.shape, t.shape)\n",
    "\n",
    "                # print(f\"完成第{i}步\")\n",
    "                predicted_noise = model(x, t)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = paddle.randn(shape=x.shape)\n",
    "                else:\n",
    "                    noise = paddle.zeros_like(x)\n",
    "                x = 1 / paddle.sqrt(alpha) * (x - ((1 - alpha) / (paddle.sqrt(1 - alpha_hat))) * predicted_noise) + paddle.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = (x.clip(-1, 1) + 1) / 2\n",
    "        x = (x * 255)\n",
    "        return x\n",
    "\n",
    "def train(args):\n",
    "    # setup_logging(args.run_name)\n",
    "    device = args.device\n",
    "    dataloader = get_data(args)\n",
    "\n",
    "    image = next(iter(dataloader))[0]\n",
    "\n",
    "    model = UNet()\n",
    "    opt = optimizer.Adam(learning_rate=args.lr, parameters=model.parameters())\n",
    "    mse = nn.MSELoss()\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
    "    # logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    l = len(dataloader)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, images in enumerate(pbar):\n",
    "            # print(images)\n",
    "            t = diffusion.sample_timesteps(images[0].shape[0])\n",
    "            x_t, noise = diffusion.noise_images(images[0], t)\n",
    "            predicted_noise = model(x_t, t)\n",
    "            loss = mse(noise, predicted_noise)  # 损失函数\n",
    "\n",
    "            opt.clear_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "\n",
    "            # print((\"MSE\", loss.item(), \"global_step\", epoch * l + i))\n",
    "            # logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            paddle.save(model.state_dict(), f\"car_models/ddpm_uncond{epoch}.pdparams\")\n",
    "            sampled_images = diffusion.sample(model, n=8)\n",
    "\n",
    "            for i in range(8):\n",
    "                img = sampled_images[i].transpose([1, 2, 0])\n",
    "                img = np.array(img).astype(\"uint8\")\n",
    "                plt.subplot(2,4,i+1)\n",
    "                plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "def launch():\n",
    "    import argparse\n",
    "\n",
    "    # 参数设置\n",
    "    class ARGS:\n",
    "        def __init__(self):\n",
    "            self.run_name = \"DDPM_Uncondtional\"\n",
    "            self.epochs = 1000\n",
    "            self.batch_size = 16\n",
    "            self.image_size = 64\n",
    "            self.dataset_path = r\"/dataset/OPIXray/train/train_crop\"\n",
    "            self.device = \"cuda\"\n",
    "            self.lr = 1.5e-4\n",
    "\n",
    "    args = ARGS()\n",
    "    train(args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    launch()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "model = UNet()\n",
    "model.set_state_dict(paddle.load(\"car_models/ddpm_uncond140.pdparams\"))   # 加载模型文件\n",
    "diffusion = Diffusion(img_size=64, device=\"cuda\")\n",
    "\n",
    "sampled_images = diffusion.sample(model, n=8)\n",
    "\n",
    "# 采样图片\n",
    "for i in range(8):\n",
    "    img = sampled_images[i].transpose([1, 2, 0])\n",
    "    img = np.array(img).astype(\"uint8\")\n",
    "    plt.subplot(2, 4,i+1)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "\"\"\"由于条件生成需要同时提供图片标签，因此我们这里自定义数据集\"\"\"\n",
    "\n",
    "# 1、将图片数据写入txt文件。flowers本来是分类数据集，这里我们把他的训练集和验证集都提取出来，当作我们生成模型的训练集。\n",
    "import os\n",
    "train_sunflower = os.listdir(\"work/flowers/pic/train/sunflower\")            # 0——向日葵\n",
    "valid_sunflower = os.listdir(\"work/flowers/pic/validation/sunflower\")       # 0——向日葵\n",
    "train_rose      = os.listdir(\"work/flowers/pic/train/rose\")                 # 1——玫瑰\n",
    "valid_rose      = os.listdir(\"work/flowers/pic/validation/rose\")            # 1——玫瑰\n",
    "train_tulip     = os.listdir(\"work/flowers/pic/train/tulip\")                # 2——郁金香\n",
    "valid_tulip     = os.listdir(\"work/flowers/pic/validation/tulip\")           # 2——郁金香\n",
    "train_dandelion = os.listdir(\"work/flowers/pic/train/dandelion\")            # 3——蒲公英\n",
    "valid_dandelion = os.listdir(\"work/flowers/pic/validation/dandelion\")       # 3——蒲公英\n",
    "train_daisy     = os.listdir(\"work/flowers/pic/train/daisy\")                # 4——雏菊\n",
    "valid_daisy     = os.listdir(\"work/flowers/pic/validation/daisy\")           # 4——雏菊\n",
    "\n",
    "with open(\"flowers_data.txt\", 'w') as f:\n",
    "    for image in train_sunflower:\n",
    "        f.write(\"work/flowers/pic/train/sunflower/\" + image + \";\" + \"0\" + \"\\n\")\n",
    "    for image in valid_sunflower:\n",
    "        f.write(\"work/flowers/pic/validation/sunflower/\" + image + \";\" + \"0\" + \"\\n\")\n",
    "    for image in train_rose:\n",
    "        f.write(\"work/flowers/pic/train/rose/\" + image + \";\" + \"1\" + \"\\n\")\n",
    "    for image in valid_rose:\n",
    "        f.write(\"work/flowers/pic/validation/rose/\" + image + \";\" + \"1\" + \"\\n\")\n",
    "    for image in train_tulip:\n",
    "        f.write(\"work/flowers/pic/train/tulip/\" + image + \";\" + \"2\" + \"\\n\")\n",
    "    for image in valid_tulip:\n",
    "        f.write(\"work/flowers/pic/validation/tulip/\" + image + \";\" + \"2\" + \"\\n\")\n",
    "    for image in train_dandelion:\n",
    "        f.write(\"work/flowers/pic/train/dandelion/\" + image + \";\" + \"3\" + \"\\n\")\n",
    "    for image in valid_dandelion:\n",
    "        f.write(\"work/flowers/pic/validation/dandelion/\" + image + \";\" + \"3\" + \"\\n\")\n",
    "    for image in train_daisy:\n",
    "        f.write(\"work/flowers/pic/train/daisy/\" + image + \";\" + \"4\" + \"\\n\")\n",
    "    for image in valid_daisy:\n",
    "        f.write(\"work/flowers/pic/validation/daisy/\" + image + \";\" + \"4\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、构建数据集\n",
    "# 数据变化，返回图片与标签\n",
    "import paddle.vision as V\n",
    "from PIL import Image\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 数据变换\n",
    "transforms = V.transforms.Compose([\n",
    "        V.transforms.Resize(80),  # args.image_size + 1/4 *args.image_size\n",
    "        V.transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "        V.transforms.ToTensor(),\n",
    "        V.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "class TrainDataFlowers(Dataset):\n",
    "    def __init__(self, txt_path=\"flowers_data.txt\"):\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            data = f.readlines()\n",
    "        self.image_paths = data[:-1]    # 最后一行是空行，舍弃\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.image_paths[index].split(\";\")\n",
    "        image = Image.open(image_path)\n",
    "        image = transforms(image)\n",
    "\n",
    "        label = int(label)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "dataset = TrainDataFlowers()\n",
    "dataloader = DataLoader(dataset, batch_size=24, shuffle=True)\n",
    "\n",
    "if __name__ == \"__main__\": # 测试数据集是否可用\n",
    "    pbar = tqdm(dataloader)\n",
    "    for i, (images, labels) in enumerate(pbar):\n",
    "        pass\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import paddle\n",
    "import copy\n",
    "import paddle.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from paddle import optimizer\n",
    "from modules import UNet_conditional, EMA\n",
    "import logging\n",
    "import numpy as np\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=500, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule()\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = paddle.cumprod(self.alpha, dim=0)\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return paddle.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = paddle.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = paddle.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = paddle.randn(shape=x.shape)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return paddle.randint(low=1, high=self.noise_steps, shape=(n,))\n",
    "\n",
    "    def sample(self, model, n, labels, cfg_scale=3):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with paddle.no_grad():\n",
    "            x = paddle.randn((n, 3, self.img_size, self.img_size))\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = paddle.to_tensor([i] * x.shape[0]).astype(\"int64\")\n",
    "                predicted_noise = model(x, t, labels)\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    cfg_scale = paddle.to_tensor(cfg_scale).astype(\"float32\")\n",
    "                    predicted_noise = paddle.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = paddle.randn(shape=x.shape)\n",
    "                else:\n",
    "                    noise = paddle.zeros_like(x)\n",
    "                x = 1 / paddle.sqrt(alpha) * (x - ((1 - alpha) / (paddle.sqrt(1 - alpha_hat))) * predicted_noise) + paddle.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = (x.clip(-1, 1) + 1) / 2\n",
    "        x = (x * 255)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    # setup_logging(args.run_name)\n",
    "    device = args.device\n",
    "    dataloader = args.dataloader\n",
    "    model = UNet_conditional(num_classes=args.num_classes)\n",
    "    opt = optimizer.Adam(learning_rate=args.lr, parameters=model.parameters())\n",
    "    mse = nn.MSELoss()\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
    "    l = len(dataloader)\n",
    "    ema = EMA(0.995)\n",
    "    ema_model = copy.deepcopy(model)\n",
    "    ema_model.eval()\n",
    "    # print(\"ema_model\", ema_model)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (images, labels) in enumerate(pbar):\n",
    "            t = diffusion.sample_timesteps(images.shape[0])\n",
    "            x_t, noise = diffusion.noise_images(images, t)\n",
    "            if np.random.random() < 0.1:\n",
    "                labels = None\n",
    "            predicted_noise = model(x_t, t, labels)\n",
    "            loss = mse(noise, predicted_noise)  # 损失函数\n",
    "\n",
    "            opt.clear_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            ema.step_ema(ema_model, model)\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "            # logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        if epoch % 30 == 0:     # 保存模型，可视化训练结果。\n",
    "            paddle.save(model.state_dict(), f\"models/ddpm_cond{epoch}.pdparams\")\n",
    "\n",
    "            labels = paddle.arange(5).astype(\"int64\")\n",
    "            # 一共采样10张图片\n",
    "            # 从左到右依次为-->向日葵，玫瑰，郁金香，蒲公英，雏菊\n",
    "            sampled_images1 = diffusion.sample(model, n=len(labels), labels=labels)\n",
    "            sampled_images2 = diffusion.sample(model, n=len(labels), labels=labels)\n",
    "            # ema_sampled_images = diffusion.sample(ema_model, n=len(labels), labels=labels)\n",
    "            for i in range(5):\n",
    "                img = sampled_images1[i].transpose([1, 2, 0])\n",
    "                img = np.array(img).astype(\"uint8\")\n",
    "                plt.subplot(2,5,i+1)\n",
    "                plt.imshow(img)\n",
    "            for i in range(5):\n",
    "                img = sampled_images2[i].transpose([1, 2, 0])\n",
    "                img = np.array(img).astype(\"uint8\")\n",
    "                plt.subplot(2,5,i+1+5)\n",
    "                plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def launch():\n",
    "    import argparse\n",
    "\n",
    "    # 参数设置\n",
    "    class ARGS:\n",
    "        def __init__(self):\n",
    "            self.run_name = \"DDPM_Uncondtional\"\n",
    "            self.epochs = 300\n",
    "            self.batch_size = 4\n",
    "            self.image_size = 64\n",
    "            self.device = \"cuda\"\n",
    "            self.lr = 1.5e-4\n",
    "            self.num_classes = 2\n",
    "            self.dataloader = dataloader\n",
    "\n",
    "\n",
    "    args = ARGS()\n",
    "    train(args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 训练\n",
    "    launch()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpaddle\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mset_state_dict(paddle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/Folding_Knife/ddpm_uncond980.pdparams\u001b[39m\u001b[38;5;124m\"\u001b[39m))   \u001b[38;5;66;03m# 加载模型文件\u001b[39;00m\n\u001b[1;32m      5\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m Diffusion(img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UNet' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
